Lab 7 - Bardi - Tara and Hanieh
 
Non-Verbal Predicates Phenomenon

- Bardi has nominal and adjectival predicates, and the copula is normally null (pp.601-610). 
- Adjectives do not really exist independent of stative verbs. 
- There is no PP either, and NPs are used with a locative verb.
- Locative case is frequently used to indicate 'static location.'
- The light verb -ni- ‘sit’ is used to indicate states; 
for instance: iilan -ni- ‘be sick’; miyala -ni- ‘be awake’ (p. 538)
- Adjectival preverbs which form stative predicates with -ni- ‘sit’ may also
combine with the light verb -joo- ‘do/say’ to form inchoatives.

Below are the detailed ways non-verbal predicates are constructed:

Null Predicates:
- The presence of copula is independent of tense and can remain null for all tenses  
- Order of subject and predicate is flexible 
- Oblique pronouns (in the predicate) used along with a location case-marked noun in the subject can make copula predicates too.

Example [doesn’t parse] (p.601):
Ginyinggi aamba galgarr.
This man widower
`This man is a widower.’
   
Clauses with -ni- ‘sit’:
- Combining the verb -ni- ‘sit’ in dfferent ways with predicative adjectives can be used as copula. 

Examples [don't parse] (p. 554)
garrja -ni- ‘be sharp’:
garrja i-ni-n ginyinggi jamooyoon.
sharp 3-sit-CONT 3MIN knife
`The knife is sharp'

Location
- providing “spatial” information
translated to ‘there was + noun + location/place (over there, in his camp)’

Assertion of existence
- informing of the presence/existence (as opposed to absence) of the subject 
- translated to ‘there is’ or ‘here is + noun’

Pointing out
- both locational and existential; uses deictic marker _jiiba_ ‘this’ 
before the place to emphasize the location of something
- translated to ‘this is it’ or ‘here it is’ 

Aspectual modification of adjectives
- -ni- as a light verb used with an adjective creating syntactic minimal pairs 
between sentences w/ complex predicate and those w/ null copula
- translated to copula as in ‘be + adjective’
Example [doesn't parse]
Garnka inin jorndi
Garnka i-ni-n jorndi
raw 3-sit-CONT still
   
Elided Verbs:
- Verbs can only be seen elided in answers to questions having 
a single noun phrase standing alone as the answer.

Example [doesn’t parse] (p.609):
Angginim goorr?
Anggi-nim goorr
what-ERG 2AUG
‘What’s wrong with you? What happened to you?’


Wh-Questions and Copula: 
- To make constituent (wh-) questions, Bardi uses a number of interrogative pronouns that usually
appear clause initially. This analysis should work together with 
the null-copula analysis of nominal non-verbal predicates. 
- I beleive this would could also be an "elided" verb way of constructing
non-verbal predicates explained above. 
  
Below is an example, which doesn't parse:
Anggaba nyinga joo?
Anggaba nyi-nga joo
who 2MIN-name 2MIN
`What’s your name?'
  
  
Translation
- According to Bowern words such as ‘hungry’ and ‘thirsty’ are primarily nouns in Bardi, not
adjectives. The noun in the ergative and the experiencer as the subject is used 
to construct a causal relation to express that one is hungry or thirsty,. (pp. 268)

- The other major use of the ergative is to mark low-animacy causers. In this 
case the subject is the high-animacy patient and it takes the subject agreement 
marker on the verb. (pp. 198)

- There is very littel evidence in the descriptive text to help with the translation of 
the three sentences for this lab. We have used the different ways of constructing 
non-verbals to translate them. Hence, multiple translations below. The page numbers are to 
show evidenced examples pages off of which we have translated the sentences. 

#15 preverb do.say
manyjal-nim alig iila i-rr-oo-j-ij
hunger-ERG feel.bad dog 3-AUG-TR-do.say-PFV
The dogs are hungry.
(p.268)

#15 verb -ni- 'sit' (hungry = sharp)
garrja i-ni-n ginyinggi jamooyoon.
sharp 3-sit-CONT 3MIN knife
`The knife is sharp'
(p.508)

#16 noun locative and -ni- 'sit.be' (park = cave)
iila-nim gardin-on i-rr-ni
dog-ERG park-LOC 3-AUG-be
The dogs are in the park.

OR 

#16 noun locative (park = cave)
iila-nim gardin-on 
dog-ERG park-LOC 
The dogs are in the park.

OR 

#16 null locative(park = beach) 
iila-nim jaala i-rr-ni
dog-ERG park 3-AUG-be
The dogs are in the park.


no evidence of such a construction but maybe:

#17 for ergative involving -ni- 'sit.be'
iila-nim i-rr-ni-irr aarli
dog-ERG 3-AUG-be-3AUG cat
The dogs are the cats.
 
 OR

 #17 for null copula 
 Ginyinggi iila aarli
 This dog cat
 `These dogs are cats.’
 
 OR 

 #17 for null copula 
 Ginyinggion iila aarli
 Ginyinggi-on iila aarli dog cat
 This-LOC 
 `These dogs are cats.’’
 
 
More parses and translations
  
  Anggaba inyarrjarrmin
  anggaba i-ny-arr-jarrmi-n
  Who sleeps? 
  can parse but can't translate yet
  
  can translate futrhter
  	#8: 11812 results
      #11: 24 results
      
    From lab 6
      #2: 12 results (possibly the result of implementation of object dropping
        this is explained more as a new ambiguity source below)
      #3: 0 results (expected at this point)
      #4: 2 results
      #5: 24 results (first test after adding negation)
      #18: 0 results (it parses in lkb but won't generate most likely because
        Bardi doesn't have determiners for nouns like "the" or "a"; it goes from
        "the dog" in English to "dog" in Bardi)
      #19: 2 results

TSDB
  Initial Run
    corpus (tsdb/home/bardi/lab7/lab6grammar/corpus)
      1.  items parsed
      2. We averaged  parses per parsed item.
      3. Our most ambiguous item got  readings.

    testsuite (tsdb/home/bardi/lab7/lab6grammar/lab7)
      1.  items parsed
      2. We averaged  parses per parsed item.
      3. Our most ambiguous item got  parses.
      4. Our most ambiguous item has  parses due to different combinations of
        

  Final Run
    corpus (tsdb/home/bardi/lab7/lab7grammar/corpus)
      1. 0 items parsed
      2. We averaged 0 parses per parsed item.
      3. Our most ambiguous item got 0 readings.

    testsuite (tsdb/home/bardi/lab7/lab7grammar/lab7)
      1.  items parsed
      2. We averaged  parses per parsed item.
      3. Our most ambiguous item(s) got  parses.
      4. A new source of ambiguity is with 
      

  Coverage
    - Initial Run
      - corpus: % coverage
      - testsuite: % coverage
    - Final Run
      - corpus: % coverage
      - testsuite: % coverage
    - Comparison
      - corpus: 
      - testsuite: 
